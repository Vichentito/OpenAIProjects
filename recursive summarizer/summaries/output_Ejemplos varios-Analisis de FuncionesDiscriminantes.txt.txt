El tema 3 trata sobre técnicas de análisis discriminante, una clasificación supervisada para el reconocimiento de patrones. Esta técnica usa una función 
lineal discriminante de Fisher para evaluar la clasificación y un test M de Box para diagnosticar hipótesis. Los datos y la notación se definen en base al 
grupo al que pertenece un nuevo dato desconocido, Xo. La regla de Fisher para dos grupos con matrices de covarianzas iguales es un problema que consta de 
maximizar la variabilidad entre grupos y minimizar la variabilidad dentro de los grupos. La puntuación discriminante (o score) de Xo es la proyección de Xo 
en la dirección discriminante WX. La regla de clasificación de Fisher indica que se clasificará al nuevo individuo Xo en el grupo 1 si W'Xo < Ww2. El ejemplo 
presentado es el caso de esclerosis múltiple, donde se muestran los vectores de medias, estadísticos y matrices de covarianzas para cada grupo.

Este ejemplo se trata del diagnóstico de Esclerosis Múltiple. Se usa la regla de discriminación lineal de Fisher para clasificar a los individuos en dos grupos, 
según los datos obtenidos de varias variables. SPSS proporciona la función canónica discriminante, los coeficientes y las puntuaciones canónicas discriminantes, 
así como los centroides. La clasificación se realiza calculando la puntuación canónica discriminante y comparándola con los centroides. El individuo Xx se 
clasificará en el grupo del centroide más cercano. Además, este ejemplo también presenta una clasificación supervisada y no supervisada para identificar 
grupos de individuos con características comunes.

En un estudio sobre la esclerosis múltiple, se registraron las respuestas a dos estimulos visuales diferentes de los ojos izquierdo y derecho de 29 
pacientes que padecían la enfermedad y 69 controles sanos. Se registraron 5 variables: edad, RISUMA, R1DIF, R2SUMA y R2DIF. El objetivo era conocer la 
regla para diseñar un test sencillo para el diagnóstico de la esclerosis multiple. Se determinó que una buena regla de clasificación sería aquella que 
fuera capaz de separar claramente a los individuos de los distintos grupos. El método de clasificación de Fisher es óptimo cuando la distribución de los 
datos es normal y las matrices de covarianzas son iguales en los dos grupos. La tasa de error aparente es un criterio optimista para evaluar si una regla 
de clasificación es buena, ya que se usa el mismo conjunto de datos para construir y evaluar la regla. Una regla será óptima cuando comete el menor número 
posible de errores en la clasificación.

Este artículo se enfoca en el análisis discriminante para evaluar si una regla de clasificación es buena. Primero, se divide la muestra de entrenamiento 
en dos partes, con una se construye la regla y con la otra se calcula la tasa de frecuencia relativa de error. Esto resulta ser ineficiente. Además, se
 presenta la tasa de error por validación cruzada (jackknife) que consiste en excluir un dato, construir la regla con los restantes, y clasificar el que 
fue excluido. Esta tasa es menos optimista que la tasa de error aparente y más eficiente que la tasa de frecuencia relativa de error. Por último, se hace 
un ejemplo con esclerosis múltiple y cancer de mama para ilustrar el uso del test M de Box para contrastar hipótesis.

Cuando se rechaza la hipótesis nula Hj: 2, = 25, una alternativa es calcular la misma dirección discriminante asumiendo matrices iguales, pero calculando 
la distancia estandarizada de la puntuación discriminante del dato que queremos clasificar a los centroides. En este caso, se proyectan todos los datos y 
se estima la varianza de las puntuaciones discriminantes dentro de cada grupo. Cuando hay información previa sobre a qué grupo es más probable que 
pertenezca un nuevo individuo que queremos clasificar, se puede incorporar en la regla de decisión utilizando las probabilidades a priori. Estas probabilidades 
a priori más usadas son 1,: probabilidad a priori para el grupo 1 y 11>: probabilidad a priori para el grupo 2. La regla de Fisher para dos grupos con matrices 
de covarianzas iguales (2,=2,) y probabilidades a priori 77, y 77> es: Clasificar al nuevo individuo Xp en
 el grupo 1 si: _, 7 iM Ie hs Mee Wh w'x) < w'| + |- Ln Z 1,.

La regla de Fisher se extiende para clasificar un nuevo dato cuando hay tres o más grupos. Esto resulta en 1) tantas funciones discriminantes como grupos 
menos uno, 2) puntuaciones discriminantes con tantas coordenadas como grupos menos una, 3) tantos centroides como grupos, 
4) los centroides con tantas coordenadas como grupos menos una, y 5) clasificamos en el grupo con el centroide más cercano a
 la puntuación discriminante del nuevo dato. Utilizando esta regla se puede clasificar por especies a los nuevos ejemplares 
de lirios. Se obtienen coeficientes de las funciones canónicas discriminantes, las cuales se evalúan en las medias de los grupos. También se 
obtienen puntuaciones en las funciones discriminantes canónicas y un bicentroide para cada grupo. Los resultados de la clasificación muestran
 que el 98% de los casos agrupados originales y validados fueron clasificados correctamente.

Las técnicas de análisis discriminante son un conjunto de técnicas estadísticas usadas para clasificar elementos en grupos o clases basándose 
en una serie de características o variables. Estas tienen numerosas aplicaciones en áreas como la medicina, ingeniería, informática, 
economía y literatura. El enfoque de Fisher trata de encontrar una buena función discriminante lineal que combina variables originales. Esta función 
se aplica a un nuevo dato para determinar a qué grupo pertenece. Geométricamente, se busca una dirección que proyecte los datos de los grupos 
conocidos y desconocidos. Una buena dirección debe separar bien las medias teniendo en cuenta la variabilidad. El nuevo dato se clasifica dentro 
del grupo con la media más cercana en la proyección.